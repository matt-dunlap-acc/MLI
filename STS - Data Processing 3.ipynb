{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc34d2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "import csv #to read in and split up all the content from the dataset input file\n",
    "import numpy as np #import numpy using np as an alias\n",
    "import pandas as pd #import pandas using pd as an alias\n",
    "import matplotlib.pyplot as plt #import matplotlib.pyplot using plt as an alias\n",
    "import seaborn as sb #import seaborn using sns as an alias\n",
    "import sys\n",
    "import codecs\n",
    "# Scikit-Learn â‰¥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder #import the encoder classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4db01caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueCards = ['Defend', 'Neutralize', 'Strike', 'Survivor', 'Acrobatics', 'Backflip', 'Bane', \n",
    "               'Blade Dance', 'Cloak And Dagger', 'Dagger Spray', 'Dagger Throw', 'Deadly Poison', \n",
    "               'Deflect', 'Dodge and Roll', 'Flying Knee', 'Outmaneuver', 'PiercingWail', \n",
    "               'Poisoned Stab', 'Prepared', 'Quick Slash', 'Slice', 'Sneaky Strike', 'Sucker Punch', \n",
    "               'Accuracy', 'All Out Attack', 'Backstab', 'Blur', 'Bouncing Flask', \n",
    "               'Calculated Gamble', 'Caltrops', 'Catalyst', 'Choke', 'Concentrate', \n",
    "               'Crippling Cloud', 'Dash', 'Distraction', 'Endless Agony', 'Escape Plan', \n",
    "               'Eviscerate', 'Expertise', 'Finisher', 'Flechettes', 'Footwork', 'Heel Hook', \n",
    "               'Infinite Blades', 'Leg Sweep', 'Masterful Stab', 'Noxious Fumes', 'Predator', \n",
    "               'Reflex', 'Riddle With Holes', 'Setup', 'Skewer', 'Tactician', 'Terror', \n",
    "               'Well Laid Plans', 'A Thousand Cuts', 'Adrenaline', 'After Image', 'Alchemize', \n",
    "               'Bullet Time', 'Burst', 'Corpse Explosion', 'Die Die Die', 'Doppelganger', 'Envenom', \n",
    "               'Glass Knife', 'Grand Finale', 'Malaise', 'Nightmare', 'Phantasmal Killer', \n",
    "               'Storm of Steel', 'Tools of the Trade', 'Unload', 'Wraith Form', 'Bandage Up',\n",
    "               'Blind', 'Dark Shackles', 'Deep Breath', 'Discovery', 'Dramatic Entrance',\n",
    "               'Enlightenment', 'Finesse', 'Flash of Steel', 'Forethought', 'Good Instincts',\n",
    "               'Impatience', 'Jack Of All Trades', 'Madness', 'Mind Blast', 'Panacea',\n",
    "               'PanicButton', 'Purity', 'Swift Strike', 'Trip', 'Apotheosis', 'Chrysalis',\n",
    "               'HandOfGreed', 'Magnetism', 'Master of Strategy', 'Mayhem', 'Metamorphosis',\n",
    "               'Panache', 'Sadistic Nature', 'Secret Technique', 'Secret Weapon', 'The Bomb',\n",
    "               'Thinking Ahead', 'Transmutation', 'Violence', 'Apparition', 'Beta', 'Bite',\n",
    "               'Expunger', 'Insight', 'J.A.X.', 'Miracle', 'Omega', 'RitualDagger', 'Safety',\n",
    "               'Shiv', 'Smite', 'Through Violence', 'Clumsy', 'Decay', 'Doubt',\n",
    "               'Injury', 'Normality', 'Pain', 'Parasite', 'Regret',\n",
    "               'Shame', 'Writhe', 'Pride', 'Venomology', 'Underhanded Strike', 'Crippling Poison',\n",
    "               'Night Terror', 'CurseOfTheBell', 'AscendersBane', 'Necronomicurse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31861fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the csv with the cleaned file\n",
    "draftDfv4 = pd.read_csv('draftDfv3.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93dec0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before drop: 187282\n",
      "After drop: 181337\n"
     ]
    }
   ],
   "source": [
    "#Delete all rows with 'ghostly' card in master_deck\n",
    "indicesToDelete = []\n",
    "index = 0\n",
    "for deck in draftDfv4['master_deck']:\n",
    "    cardList = deck.split(',')\n",
    "    for card in cardList:\n",
    "        if \"+\" in card:\n",
    "            card = card.split(\"+\")[0]\n",
    "        if not(card in uniqueCards):\n",
    "            indicesToDelete.append(index)\n",
    "    index += 1\n",
    "print(f\"Before drop: {len(draftDfv4)}\")\n",
    "draftDfv5 = draftDfv4.drop(indicesToDelete, axis=0)\n",
    "print(f\"After drop: {len(draftDfv5)}\")\n",
    "draftDfv5 = draftDfv5.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "574b52cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "upgradedCards = []\n",
    "for card in uniqueCards:\n",
    "    upgrade1 = card + \"+1\"\n",
    "    upgrade2 = card + \"+2\"\n",
    "    upgrade3 = card + \"+3\"\n",
    "    upgradedCards.append(upgrade1)\n",
    "    upgradedCards.append(upgrade2)\n",
    "    upgradedCards.append(upgrade3)\n",
    "allPossibleCards = upgradedCards + uniqueCards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "088751b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary from allPossibleCards and initialize to 0.\n",
    "#This dict will be used to initialize \n",
    "type_list = []\n",
    "for card in allPossibleCards:\n",
    "    type_list.append('int64')\n",
    "columnsByType = dict(zip(allPossibleCards, type_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02ad6d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty df and initialize column names\n",
    "newDf1 = pd.DataFrame(columns = allPossibleCards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dcf1044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set types for df columns\n",
    "newDf1 = newDf1.astype(columnsByType, copy=True, errors='raise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c17b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotEncodedDfs = []\n",
    "for num in range(0, 19):\n",
    "    oneHotEncodedDfs.append(newDf1.copy(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b367d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 done.\n",
      "20000 done.\n",
      "30000 done.\n",
      "40000 done.\n",
      "50000 done.\n",
      "60000 done.\n",
      "70000 done.\n",
      "80000 done.\n",
      "90000 done.\n",
      "100000 done.\n",
      "110000 done.\n",
      "120000 done.\n",
      "130000 done.\n",
      "140000 done.\n",
      "150000 done.\n",
      "160000 done.\n",
      "170000 done.\n",
      "180000 done.\n",
      "190000 done.\n"
     ]
    }
   ],
   "source": [
    "#Split training data into 19 excel spreadsheets, 10000 rows each\n",
    "lowerLimit = 0\n",
    "cardCountKeyValue = dict(zip(newDf1.columns, [0] * len(newDf1.columns)))\n",
    "\n",
    "for oneHotEncodedDf in oneHotEncodedDfs:\n",
    "    if lowerLimit == 180000:\n",
    "        for card in draftDfv5['master_deck'][180000:]:\n",
    "            cardList = card.split(',')\n",
    "            for card1 in cardList:\n",
    "                cardCountKeyValue[card1] += 1\n",
    "            oneHotEncodedDf.loc[len(oneHotEncodedDf.index)] = list(cardCountKeyValue.values())\n",
    "            cardCountKeyValue = dict(zip(oneHotEncodedDf.columns, [0] * len(oneHotEncodedDf.columns)))\n",
    "    else:\n",
    "        for card in draftDfv5['master_deck'][lowerLimit:lowerLimit+10000]:\n",
    "            cardList = card.split(',')\n",
    "            for card1 in cardList:\n",
    "                cardCountKeyValue[card1] += 1\n",
    "            oneHotEncodedDf.loc[len(oneHotEncodedDf.index)] = list(cardCountKeyValue.values())\n",
    "            cardCountKeyValue = dict(zip(oneHotEncodedDf.columns, [0] * len(oneHotEncodedDf.columns)))\n",
    "    oneHotEncodedDf.to_csv('D:\\STS Master Deck - OneHot Encoded\\DF' + str(lowerLimit) + '.csv')\n",
    "    lowerLimit += 10000\n",
    "    print(str(lowerLimit) + \" done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4665de11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['master_deck', 'current_hp_per_floor', 'victory', 'max_hp_per_floor',\n",
       "       'ascension_level'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draftDfv5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce049a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['current_hp_per_floor', 'victory', 'max_hp_per_floor', 'ascension_level']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(draftDfv5.columns)\n",
    "columns.remove('master_deck')\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b896ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done.\n",
      "10000 done.\n",
      "20000 done.\n",
      "30000 done.\n",
      "40000 done.\n",
      "50000 done.\n",
      "60000 done.\n",
      "70000 done.\n",
      "80000 done.\n",
      "90000 done.\n",
      "100000 done.\n",
      "110000 done.\n",
      "120000 done.\n",
      "130000 done.\n",
      "140000 done.\n",
      "150000 done.\n",
      "160000 done.\n",
      "170000 done.\n",
      "180000 done.\n"
     ]
    }
   ],
   "source": [
    "def addColumnsToDf(dfExtension):\n",
    "    #pull 10k rows from the rest of draftDfv5's columns and add them to the csv holding the \n",
    "    #data for the master_deck\n",
    "    columns = list(draftDfv5.columns)\n",
    "    columns.remove('master_deck')\n",
    "    lowerLimit = dfExtension\n",
    "    \n",
    "    df = pd.read_csv('D:\\STS Master Deck - With Max Floor\\DF'+ str(dfExtension) + '.csv', delimiter=',', index_col=False)\n",
    "    for columnName in columns:\n",
    "        #if the column name is current or max hp\n",
    "        #clean the data\n",
    "        columnValuesToAdd = []\n",
    "        requiresCleaning = False\n",
    "        if (columnName != 'victory' and columnName != 'ascension_level'):\n",
    "            requiresCleaning = True\n",
    "        if lowerLimit == 180000:\n",
    "            break\n",
    "            for row in draftDfv5[columnName][180000:]:\n",
    "                if (requiresCleaning):\n",
    "                    row = row.strip('][').replace(' ', '').split(',')\n",
    "                    columnValuesToAdd.append(row[32])\n",
    "\n",
    "        else:\n",
    "            for row in draftDfv5[columnName][lowerLimit:lowerLimit + 10000]:\n",
    "                if (requiresCleaning):\n",
    "                    row = row.strip('][').replace(' ', '').split(',')\n",
    "                    columnValuesToAdd.append(row[32])\n",
    "                else:\n",
    "                    columnValuesToAdd.append(row)\n",
    "        df.insert(0, columnName, columnValuesToAdd, True)\n",
    "    df.to_csv('D:\\STS Master Deck - With Max Floor\\DF' + str(lowerLimit) + '.csv', index_col=False)\n",
    "    print(str(dfExtension) + \" done.\")\n",
    "        \n",
    "for dfExtension in range(0, 190000, 10000):\n",
    "    addColumnsToDf(dfExtension)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "472607fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeRowsWithZeroCurrentHealth(dfExtension):\n",
    "    indicesToRemove = []\n",
    "    df = pd.read_csv('D:\\STS Master Deck - OneHot Encoded\\DF'+ str(dfExtension) + '.csv', delimiter=',', index_col=False)\n",
    "    row = 0\n",
    "    \n",
    "    for currentHealth in df['current_hp_per_floor']:\n",
    "        if currentHealth == 0:\n",
    "            indicesToRemove.append(row)\n",
    "        row += 1\n",
    "    df = df.drop(indicesToRemove, axis=0)\n",
    "    df.to_csv('D:\\STS Master Deck - OneHot Encoded\\DF' + str(dfExtension) + '.csv', index=False)\n",
    "\n",
    "def removeUnwantedColumn(dfExtension):\n",
    "    df = pd.read_csv('D:\\STS Master Deck - OneHot Encoded\\DF'+ str(dfExtension) + '.csv', delimiter=',', index_col=False)\n",
    "    df = df.drop('Unnamed: 0', axis=1)\n",
    "    df.to_csv('D:\\STS Master Deck - OneHot Encoded\\DF' + str(dfExtension) + '.csv', index=False)\n",
    "\n",
    "for dfExtension in range(0, 180000, 10000):\n",
    "    removeUnwantedColumn(dfExtension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f114a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
